---
title: "Logistic Regression Inference"
author: "Lucy D'Agostino McGowan"
footer:  "[Dr. Lucy D'Agostino McGowan](https://lucymcgowan.com)"
logo: "img/favicon.png"
editor: source
format: 
  revealjs: 
    theme: [custom.scss]
    slide-number: true
    chalkboard: true
knitr:
  opts_chunk: 
    code-fold: true
    echo: true
---


## Hypothesis test

```{r child = "setup.Rmd"}
```


* **null hypothesis** $H_0: \beta_1 = 0$ 
* **alternative hypothesis** $H_A: \beta_1 \ne 0$


## Logistic regression test statistic

<br><br>


$$z = \frac{\hat\beta_1}{SE_{\hat\beta_1}}$$


## Logistic regression test statistic

::: question
How is this different from the test statistic for _linear regression_?
:::


$$z = \frac{\hat\beta_1}{SE_{\hat\beta_1}}$$



## Logistic regression test statistic {.small}

::: question
How is this different from the test statistic for _linear regression_?
:::

$$\color{red}z = \frac{\hat\beta_1}{SE_{\hat\beta_1}}$$

>* The $z$ denotes that this is a $z$-statistic
> * What does this mean? **Instead of using a $t$ distribution, we use a normal distribution to calculate the confidence intervals and p-values**


## Logistic regression confidence interval

::: question
What do you think goes in this blank to calculate a confidence interval (instead of $t^*$ as it was for _linear regression_)?
::


$$\hat\beta_1 \pm [\_^*] SE_{\hat\beta_1}$$



## Logistic regression confidence interval {.small}

::: question
What do you think goes in this blank to calculate a confidence interval (instead of $t^*$ as it was for _linear regression_)?
:::

$$\hat\beta_1 \pm [\color{red}z^*] SE_{\hat\beta_1}$$

> * $z^∗$ is found using the normal distribution and the desired level of confidence

. . .


```{r}
#| code-fold: false
qnorm(0.975)
```




## Logistic regression confidence interval {.small}

::: question
Where are my degrees of freedom when calculating $z^*$?
:::

$$\hat\beta_1 \pm [\color{red}z^*] SE_{\hat\beta_1}$$


* $z^∗$ is found using the normal distribution and the desired level of confidence

```{r}
#| code-fold: false
qnorm(0.975)
```

> * The normal distribution doesn't need to know your sample size _but it does rely on reasonably large sample_



## Logistic regression confidence interval

* $\hat\beta_1$ measures the change in log(odds) for every unit change in the predictor. What if I wanted a confidence interval for the **odds ratio**?


$$\hat\beta_1 \pm [\color{red}z^*] SE_{\hat\beta_1}$$



## Logistic regression confidence interval

::: question
How do you convert log(odds) to odds?
:::

* $\hat\beta_1$ measures the change in log(odds) for every unit change in the predictor. What if I wanted a confidence interval for the **odds ratio**?


$$\hat\beta_1 \pm [\color{red}z^*] SE_{\hat\beta_1}$$



## Logistic regression confidence interval

::: question
How do you convert log(odds) to odds?
:::

* $\hat\beta_1$ measures the change in log(odds) for every unit change in the predictor. What if I wanted a confidence interval for the **odds ratio**?


$$e^{\hat\beta_1 \pm [\color{red}z^*] SE_{\hat\beta_1}}$$


## Let's try it in R! {.small}

::: question
We are interested in the relationship between Backpack weight and Back problems.
:::


```{r}
#| code-fold: false
library(Stat2Data)
data("Backpack")
mod <- glm(BackProblems ~ BackpackWeight, 
    data = Backpack, 
    family = "binomial")

exp(coef(mod))
```

> * How do you interpret the Odds ratio?
>   * A one unit increase in backpack weight yields a 1.04-fold increase in the odds of back problems



## Let's try it in R! {.small}


```{r}
#| code-fold: false
confint(mod)
exp(confint(mod))
```


> * How do you interpret the Odds ratio?
>    * A one unit increase in backpack weight yields a 1.04-fold increase in the odds of back problems
> * What is my null hypothesis?
>   * $H_0:\beta_1 = 0$
>   * $H_A: \beta_1 \neq 0$
> * What is the result of this hypothesis test at the $\alpha = 0.05$ level?


## Log Likelihood {.small}

> * "goodness of fit" measure
> * **higher** log likelihood is better
> * Both AIC and BIC are calculated using the **log likelihood**
>    * $\Large f(k) - 2 \log\mathcal{L}$
> * $\color{red}{- 2 \log\mathcal{L}}$ - this is called the **deviance**
> * Similar to the _nested F-test_ in linear regression, in logistic regression we can compare $-2\log\mathcal{L}$ for models with and without certain predictors
> * $-2\log\mathcal{L}$ follows a $\chi^2$ distribution with $n - k - 1$ degrees of freedom.
> *  The difference $(-2\log\mathcal{L}_1)-(-2\log\mathcal{L}_2)$ follows a $\chi^2$ distribution with $p$ degrees of freedom (where $p$ is the difference in the number of predictors between Model 1 and Model 2)



## Likelihood ratio test {.small}

> * For example, if we wanted to test the following hypothesis:
>    * $H_0: \beta_1 = 0$
>    * $H_A: \beta_1 \neq 0$
> * We could compute the difference between the deviance for a model with $\beta_1$ and without $\beta_1$.
>    * Model 1: $log(odds) = \beta_0$
>    * Model 2: $log(odds) = \beta_0 + \beta_1x$
  


## Likelihood ratio test {.small}

::: question
Are these models nested?
:::

* For example, if we wanted to test the following hypothesis:
  * $H_0: \beta_1 = 0$
  * $H_A: \beta_1 \neq 0$
* We could compute the difference between the deviance for a model with $\beta_1$ and without $\beta_1$.
  * Model 1: $log(odds) = \beta_0$
  * Model 2: $log(odds) = \beta_0 + \beta_1x$



## Likelihood ratio test {.small}

::: question
What are the degrees of freedom for the deviance for Model 1?
:::

* For example, if we wanted to test the following hypothesis:
  * $H_0: \beta_1 = 0$
  * $H_A: \beta_1 \neq 0$
* We could compute the difference between the deviance for a model with $\beta_1$ and without $\beta_1$.
  * Model 1: $log(odds) = \beta_0$ 
  * Model 2: $log(odds) = \beta_0 + \beta_1x$ 
  

## Likelihood ratio test {.small}

::: question
What are the degrees of freedom for the deviance for Model 1?
:::

* For example, if we wanted to test the following hypothesis:
  * $H_0: \beta_1 = 0$
  * $H_A: \beta_1 \neq 0$
* We could compute the difference between the deviance for a model with $\beta_1$ and without $\beta_1$.
  * Model 1: $log(odds) = \beta_0$ `r emo::ji("right_arrow")` $-2\log\mathcal{L}_1$, df = $n-1$
  * Model 2: $log(odds) = \beta_0 + \beta_1x$ 



## Likelihood ratio test {.small}

::: question
What are the degrees of freedom for the deviance for Model 2?
:::

* For example, if we wanted to test the following hypothesis:
  * $H_0: \beta_1 = 0$
  * $H_A: \beta_1 \neq 0$
* We could compute the difference between the deviance for a model with $\beta_1$ and without $\beta_1$.
  * Model 1: $log(odds) = \beta_0$ `r emo::ji("right_arrow")` $-2\log\mathcal{L}_1$, df = $n-1$
  * Model 2: $log(odds) = \beta_0 + \beta_1x$ 
  

## Likelihood ratio test {.small}

::: question
What are the degrees of freedom for the deviance for Model 2?
:::

* For example, if we wanted to test the following hypothesis:
  * $H_0: \beta_1 = 0$
  * $H_A: \beta_1 \neq 0$
* We could compute the difference between the deviance for a model with $\beta_1$ and without $\beta_1$.
  * Model 1: $log(odds) = \beta_0$ `r emo::ji("right_arrow")` $-2\log\mathcal{L}_1$, df = $n-1$
  * Model 2: $log(odds) = \beta_0 + \beta_1x$ `r emo::ji("right_arrow")` $-2\log\mathcal{L}_2$, df = $n-2$



## Likelihood ratio test

* We are interested in the "drop in deviance", the deviance in Model 1 minus the deviance in Model 2

. . .

$$(-2\log\mathcal{L}_1) - (-2\log\mathcal{L}_2)$$



## Likelihood ratio test {.small}

::: question
What do you think the degrees of freedom are for this difference?
:::

* We are interested in the "drop in deviance", the deviance in Model 1 minus the deviance in Model 2

$$(-2\log\mathcal{L}_1) - (-2\log\mathcal{L}_2)$$

> * df: $(n-1) - (n-2) = 1$



## Likelihood ratio test {.small}

::: question
What is the null hypothesis again?
:::

* We are interested in the "drop in deviance", the deviance in Model 1 minus the deviance in Model 2


$$(-2\log\mathcal{L}_1) - (-2\log\mathcal{L}_2)$$ 

`r emo::ji("point_up")` test statistic


* df: $(n-1) - (n-2) = 1$



## Likelihood ratio test {.small}

::: question
How do you think we compute a p-value for this test?
:::

* We are interested in the "drop in deviance", the deviance in Model 1 minus the deviance in Model 2


$$(-2\log\mathcal{L}_1) - (-2\log\mathcal{L}_2)$$

`r emo::ji("point_up")` test statistic

* df: $(n-1) - (n-2) = 1$

. . .

```{r, eval = FALSE}
#| code-fold: false
pchisq(L_0 - L, df = 1, lower.tail = FALSE)
```



## Let's try it in R! {.small}

```{r}
#| code-fold: false
data(MedGPA)
glm(Acceptance ~ GPA, data = MedGPA, family = "binomial") %>%
  summary()
```



## Let's try it in R! {.small}

::: question
What is the "drop in deviance"?
::: 

::: {layout-ncol=2}

```{r}
#| code-fold: false
data(MedGPA)
glm(Acceptance ~ GPA, data = MedGPA, family = "binomial") %>%
  summary()
```
###

> *  75.8 - 56.8 = 19

:::

## Let's try it in R! {.small}

::: question
What are the degrees of freedom for this difference?
:::

::: {layout-ncol=2}
```{r}
#| code-fold: false
data(MedGPA)
glm(Acceptance ~ GPA, data = MedGPA, family = "binomial") %>%
  summary()
```

###

*  75.8 - 56.8 = 19

:::

## Let's try it in R! {.small}

::: question
What are the degrees of freedom for this difference?
:::

::: {layout-ncol=2}
```{r}
#| code-fold: false
data(MedGPA)
glm(Acceptance ~ GPA, data = MedGPA, family = "binomial") %>%
  summary()
```

###

*  75.8 - 56.8 = 19
* df: 1

:::


## Let's try it in R! {.small}

::: question
What is the result of the hypothesis test? How do you interpret this?
::: 

:::: columns

::: column

```{r}
#| code-fold: false
data(MedGPA)
glm(Acceptance ~ GPA, data = MedGPA, family = "binomial") %>%
  summary()
```

:::

::: column

*  75.8 - 56.8 = 19
* df: 1

```{r}
#| code-fold: false
pchisq(19, 1, lower.tail = FALSE)
```

:::

::::
