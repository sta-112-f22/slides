---
title: "Prediction intervals"
author: "Lucy D'Agostino McGowan"
footer:  "[Dr. Lucy D'Agostino McGowan](https://lucymcgowan.com)"
logo: "img/favicon.png"
editor: source
format: 
  revealjs: 
    theme: [custom.scss]
    slide-number: true
    chalkboard: true
knitr:
  opts_chunk: 
    code-fold: true
    echo: true
---


```{r, child = "setup.rmd"}
```


```{r}
#| echo: false
magnolia_data <- tibble(
  observation = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 
                  19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 
                  34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 
                  49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 
                  64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 
                  79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 
                  94, 95, 96, 97, 98, 99, 100), 
  leaf_length = c(12.53, 24.92, 12.49, 18.23, 23.5, 21.69, 12.23, 4.61, 16.4, 
                  20.51, 16.95, 17.98, 12.45, 19.48, 19.44, 20.89, 28.36, 5.62, 
                  18.03, 14.42, 19.05, 18.38, 12.44, 7.67, 8.33, 15.43, 9.45,
                  9.07, 16.48, 9.68, 7.87, 25.48, 11.69, 13.74, 7.66, 25.95,
                  21.84, 13.86, 13.3, 14.84, 10.59, 11.7, 15.85, 14.96, 16.55,
                  20.42, 13.91, 18.6, 4.38, 23.35, 19.35, 11.43, 25.07, 11.28, 
                  15.58, 21.81, 14.19, 4.72, 9.43, 11.02, 16.62, 28.23, 15.49, 
                  13.17, 13.11, 14.6, 19.85, 17.77, 26.18, 16.69, 19.83, 18.62,
                  17, 21.86, 14.29, 17.07, 13.46, 14.41, 25.83, 17.59, 12.52, 
                  18.03, 13.64, 16.58, 23.33, 12.01, 17.29, 9.95, 9.33, 3.66, 
                  13.71, 16.18, 14.73, 4.24, 11.95, 13.5, 20.08, 9.93, 12.57,
                  16.18), 
  leaf_width = c(5.1, 8.81, 8.21, 4.78, 13.62, 11.29, 7.68, 4.03, 9.4, 3.1, 
                 7.94, 9.38, 5.92, 13.77, 11.85, 10.9, 12.08, 4.23, 13, 14.84, 
                 10.98, 14.21, 7.56, 2.84, 7.6, 3.32, 4.76, 10.6, 10.58, 4.33,
                 5.9, 2.36, 3.36, 10.58, 7.32, 12.04, 4.64, 5.79, 4.28, 9.93,
                 12.33, 11.56, 12.57, 9.02, 2.39, 11.7, 9.64, 7.82, 5.26, 7.6,
                 4.68, 2.16, 11.46, 6.58, 2.84, 5.35, 11.71, 12.17, 5.9, 5.31,
                 9.04, 12.28, 2.31, 11.5, 12.09, 4.77, 11.09, 6.8, 8.44, 4.91,
                 10.8, 13.75, 5.3, 13.8, 2.71, 12.07, 6.54, 7.45, 7.16, 11.74, 
                 8.57, 4.69, 7.87, 8.8, 11.18, 16.33, 10.43, 9.07, 8.4, 5.82, 
                 8.94, 6.05, 3.94, 8.79, 8.51, 7.09, 10.68, 8.56, 7.91, 14.05)
)

```

## confidence intervals {.center}

If we use the same sampling method to select different samples and computed an interval estimate for each sample, we would expect the true population parameter ( $\beta_1$ ) to fall within the interval estimates 95% of the time.


## Confidence interval for $\hat\beta_1$

::: {.question}
How do we calculate the confidence interval for the slope?
:::


$$\hat\beta_1\pm t^*SE_{\hat\beta_1}$$


## How do we calculate it in R? {.small}


* In with the `confint` function:

```{r}
#| code-fold: false

mod <- lm(leaf_length ~ leaf_width, magnolia_data)
summary(mod)
confint(mod)
```


## How do we calculate it in R? {.small}

* "by hand"


```{r}
#| code-fold: false
t_star <- qt(0.025, df = nrow(magnolia_data) - 2, lower.tail = FALSE)
# or
t_star <- qt(0.975, df =  nrow(magnolia_data) - 2)
```

::: {layout-ncol=2}

```{r}
#| code-fold: false

0.4386 - t_star * 0.1552
```

```{r}
#| code-fold: false

0.4386 + t_star * 0.1552
```
:::


## Confidence intervals {.small}

There are `r emo::ji("v")` other types of confidence intervals we may want to calculate

> * The confidence interval for the **mean response** in $y$ for a given $x^*$ value
> * The confidence interval for an **individual response** $y$ for a given $x^*$ value
> * Why are these different? Which do you think is easier to estimate?
> It is **harder** to predict one response than to predict a mean response. What does this mean in terms of the standard error?
> * The SE of the prediction interval is going to be **larger**


## Confidence intervals {.small}

**confidence interval for** $\mu_y$ and **prediction interval**


$$ \hat{y}\pm t^* SE$$

* $\hat{y}$ is the predicted $y$ for a given $x^*$
* $t^*$ is the critical value for the $t_{n-2}$ density curve
* $SE$ takes `r emo::ji("v")` different values depending on which interval you're interested in

. . .

* $SE_{\hat\mu}$

. . .

* $SE_{\hat{y}}$

. . .

::: {.question .small}
Which will be larger?
:::
---

## Confidence intervals {.small}

**confidence interval for** $\mu_y$ and **prediction interval**


$$\hat{y}\pm t^* SE$$

* $\hat{y}$ is the predicted $y$ for a given $x^*$
* $t^*$ is the critical value for the $t_{n-2}$ density curve
* $SE$ takes `r emo::ji("v")` different values depending on which interval you're interested in
* $SE_{\hat\mu} = \hat{\sigma}_\epsilon\sqrt{\frac{1}{n}+\frac{(x^*-\bar{x})^2}{\Sigma(x-\bar{x})^2}}$
* $SE_{\hat{y}}=\hat{\sigma}_\epsilon\sqrt{1 + \frac{1}{n}+\frac{(x^*-\bar{x})^2}{\Sigma(x-\bar{x})^2}}$

. . .

::: {.question .small}
* What is the difference between these two equations?
:::

---

## Confidence intervals {.small}

**confidence interval for** $\mu_y$ and **prediction interval**


$$\hat{y}\pm t^* SE$$


* $\hat{y}$ is the predicted $y$ for a given $x^*$
* $t^*$ is the critical value for the $t_{n-2}$ density curve
* $SE$ takes `r emo::ji("v")` different values depending on which interval you're interested in
* $SE_{\hat\mu} = \hat{\sigma}_\epsilon\sqrt{\frac{1}{n}+\frac{(x^*-\bar{x})^2}{\Sigma(x-\bar{x})^2}}$
* $SE_{\hat{y}}=\hat{\sigma}_\epsilon\sqrt{\color{red}1 + \frac{1}{n}+\frac{(x^*-\bar{x})^2}{\Sigma(x-\bar{x})^2}}$

. . .

* an individual response will vary from the mean response $\mu_y$ with a standard deviation of $\sigma_\epsilon$

## Let's do it in R! {.small}


```{r}
#| eval: false
#| code-fold: false
mod <- lm(leaf_length ~ leaf_width, data = magnolia_data)
predict(mod) 
```

```{r, echo = FALSE}
#| echo: false
mod <- lm(leaf_length ~ leaf_width, data = magnolia_data)
predict(mod) %>% head(3)
```

. . .

```{r}
#| eval: false
#| code-fold: false
mod <- lm(leaf_length ~ leaf_width, data = magnolia_data)
predict(mod, interval = "confidence") 
```

```{r, echo = FALSE}
#| echo: false
mod <- lm(leaf_length ~ leaf_width, data = magnolia_data)
predict(mod, interval = "confidence") %>% head(3)
```

. . .

```{r}
#| eval: false
#| code-fold: false
mod <- lm(leaf_length ~ leaf_width, data = magnolia_data)
predict(mod, interval = "prediction") 
```

`## WARNING predictions on current data refer to _future_ responses`

```{r}
#| echo: false
mod <- lm(leaf_length ~ leaf_width, data = magnolia_data)
predict(mod, interval = "prediction") %>% head(3)
```



## Let's do it in R! {.small}

What if we have new data?

```{r}
#| code-fold: false
new_magnolia_data <- data.frame(
  leaf_width = c(5, 7.2, 4.3)
)
new_magnolia_data
```


. . .

```{r}
#| code-fold: false
predict(
  mod, 
  newdata = new_magnolia_data, 
  interval = "prediction")
```

## {{< fa laptop >}} `Aplication Exercise`

1. Open `appex-12.qmd`
2. You are interested in the predicted Porsche Price for Porsche cars that have 50,000 miles previously driven on average. Calculate this value with an appropriate confidence interval.
3. You are interested in the predicted Porsche Price for a particular Porsche with 40,000 miles previously driven. Calculate this value with an appropriate confidence interval.

```{r}
#| echo: false

countdown::countdown(4)
```

